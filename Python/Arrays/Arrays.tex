\lab{Essentials}{NumPy}{NumPy}
\label{lab:Essentials_NumPy}

\section*{Why Arrays?}
\begin{problem}
Let's begin with a simple demonstration of why arrays are important for numerical computation.
Why use arrays when Python already has a reasonably efficient list object?
In this demonstration, we will try squaring a matrix.
The matrix will be represented as a two dimensional list (i.e. a list of lists).

Write a function that will accept two matrices (two dimensional list), $A$ and $B$, and return $AB$ following the usual rules of matrix multiplication.
\begin{lstlisting}
k = 10
a = [range(i, i+k) for i in range(0, k**2, k)]
\end{lstlisting}
Time how long your function takes to square matrices for increasing values of \li{k}.
In IPython you can time how long it takes for a line of code to execute by prefacing it with \li{\%timeit}, for example:
\begin{lstlisting}
%timeit range(100)
\end{lstlisting}
\li{\%timeit} runs the line of code multiple times.
If you only want it to run once (for example if you expect it to take a long time), use \li{\%time} instead.

Now import NumPy and create a NumPy array, $b$ as shown below.
We demonstrate how to square NumPy arrays as matrices below.
\li{b*b} does not square the array, but rather multiplies $b$ with itself element-wise.
To get matrix multiplication for NumPy arrays, you must use \li{np.dot}
\begin{lstlisting}
import numpy as np
b = np.array([range(i, i+k) for i in range(0, k**2, k)])
np.dot(b, b)
\end{lstlisting}
Time how long NumPy takes to square arrays for increasing sizes of \li{k}.

What do you notice about the time needed to square a two dimensional list vs. a two dimensional NumPy array?

% Below is a comparison of runtimes needed to square a matrix
% \begin{center}
% \begin{tabular}{|c|l|l|}
% \hline
%  Data Structure & Size & Time (s) \\ \hline
%  Python List & $1\times1$ & 0.0000181198 \\ \cline{2-3}
%       & $10\times10$ & 0.0002758503 \\ \cline{2-3}
%       & $100\times100$ & 0.1336028576 \\ \cline{2-3}
%       & $1000\times1000$ & 200.4009799957 \\ \hline \hline
%  NumPy Array & $1\times1$ & 0.0000298023 \\ \cline{2-3}
%       & $10\times10$ & 0.0000109673 \\ \cline{2-3}
%       & $100\times100$ & 0.0009210110 \\ \cline{2-3}
%       & $1000\times1000$ & 2.1682999134 \\ \hline
% \end{tabular}
% 
% \end{center}
\end{problem}


\section*{NumPy}
NumPy is a fundamental package for scientific computing with Python.
It provides an efficient arbitrary-dimensional array object for fast computations.
This lab will focus on how to use these powerful objects.
NumPy is commonly imported as shown below.

\begin{lstlisting}
: import numpy as np
\end{lstlisting}
Before beginning this lab, it will be useful to understand certain concepts and terms used to describe NumPy arrays.

\subsection*{$N$-Dimensions}
One, two, and three dimensional arrays are easy to visualize.
But how do we visualize a four, ten, or fifteen dimensional array?
NumPy arrays are best thought of as arrays within arrays.
A one dimensional array consists of only elements.
A two dimensional array is really just an array containing arrays which contain elements.
Extending this metaphor, a three dimensional array is an array of arrays of arrays.
Can you guess what a five dimensional array is?
Let's define a three dimensional array.

\begin{lstlisting}
: arr = np.random.randint(50, size=(5, 4, 3))
\end{lstlisting}

Arrays have several attributes.
We use \emph{shape} and \emph{size} to describe the how big an array is.
\emph{Shape} tells how how many dimensions an array has and how big each dimension is.
\emph{Size} gives the total number of elements in the array.

\begin{lstlisting}
: arr.shape
(5, 4, 3)
: arr.size
60
\end{lstlisting}

If we want to know how much memory an array takes to store, we can use \li{arr.nbytes}.
The number of bytes is dependent on the data type (\emph{dtype}) of the array.
The data types that NumPy uses are different from Python data types.
An integer in NumPy is not the same as an integer Python.
Remembering this is vital.
NumPy uses machine data types to speed up calculations.
However, these datatypes are susceptible to a problem called \emph{overflow}.
A 64 bit integer has enough bits to represent integers between $-9,223,372,036,854,775,808$ and $9,223,372,036,854,775,807$.
If we have an array with $-9,223,372,036,854,775,808$ and we decide to subtract $1$, the integer wraps around and becomes $9,223,372,036,854,775,807$!  

\begin{lstlisting}
: arr.dtype
dtype('int64')
: arr.nbytes
480
\end{lstlisting}

Each element of the array has a unique address that describes it location.
Indexing always starts at $0$.
Also, like Python lists, negative indices are valid and count from the tail of the array.
We will discuss indexing in detail later in this lab.

\begin{lstlisting}
: arr[0, 0, 0] # returns the first element of arr
: arr[-1, -1, -1] #returns the last element of arr
\end{lstlisting}

\section*{Creating Arrays}
NumPy has several functions for creating and initializing arrays.
When creating an array, we can optionally specify the data type that is stored in the array.
NumPy arrays only store elements of the same data type, however, that data type can be any arbitrary object.
The array order dictates how the array is laid out in memory.
Two common layouts are C order and Fortran order.
C ordered arrays are also known as row-major arrays.
This means that the fastest changing index correspond to the rows of the array.
This is because rows are stored in contiguous blocks in memory.
Fortran ordered arrays are column-major.
Another common way of saying this is that an array is C contiguous or Fortran Contiguous.
Not all arrays are C contiguous or Fortran contiguous, but it is useful to understand the distinction.
Let's look at a few of the ways we can create arrays in NumPy.
\begin{itemize}
\item \li{np.array}: Makes an array from a Python list or tuple. Can also be used to make a new array based on an old one, possibly with a changed datatype.
\item \li{np.empty}: Allocates an array of a specific size without initializing the elements.
\item \li{np.empty_like}: Allocates a new uninitialized array with the same properties as the input array.
\item \li{np.ones}: Allocates and array and initializes each element to $1$.
\item \li{np.ones_like}: Allocates a new array of ones with the same properties as the input array.
\item \li{np.zeros}: Allocates and array and initializes each element to $0$.
\item \li{np.zeros_like}: Allocates a new array of zeros with the same properties as the input array.
\item \li{np.identity}: Allocates a 2D array array with the main diagonal initialized to $1$ and zeros everywhere else.
\end{itemize}

\subsection*{Indexing Arrays}
\subsubsection*{Array Views and Copies}
Before we begin accessing arrays, it is important to understand that NumPy has two ways of returning an array.
Slice operations always return a \emph{view} and fancy indexing always returns a \emph{copy}.
Understand that even though they may look the same, views and copies completely different.

Views are special arrays that reference other arrays.
Changing elements in a view changes the array it references.
Below we demonstrate the behavior of a view.
Notice that \li{c} looks like a copy of \li{b}, but it is, in fact, not at all.
\begin{lstlisting}
: b = np.arange(25).reshape(5,5); b
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14],
       [15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24]])
: c = b[:]; c #looks like c is a copy of b
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14],
       [15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24]])
: id(c) == id(b) #We have unique objects
False
: c[2] = 500; c
array([[  0,   1,   2,   3,   4],
       [  5,   6,   7,   8,   9],
       [500, 500, 500, 500, 500],
       [ 15,  16,  17,  18,  19],
       [ 20,  21,  22,  23,  24]])
: b #changing c also changed b!
array([[  0,   1,   2,   3,   4],
       [  5,   6,   7,   8,   9],
       [500, 500, 500, 500, 500],
       [ 15,  16,  17,  18,  19],
       [ 20,  21,  22,  23,  24]])
\end{lstlisting}

The reason that changing the array \li{c} also changed the array \li{b} is because \li{c} and \li{b} share the same memory, even though they are different Python objects.
Views reduce the overhead of making copies of arrays and are useful when we want to change certain parts of the array.
This is somewhat analagous to pointers in C, where two pointers can point to the same place in memory.

A copy of an array is a separate array that is allocated separately.
\begin{lstlisting}
: b = np.arange(25).reshape(5, 5); b
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14],
       [15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24]])
: c = b.copy()
: id(c) == id(b) #we still have separate objects
False
: c[2] = 500
array([[  0,   1,   2,   3,   4],
       [  5,   6,   7,   8,   9],
       [500, 500, 500, 500, 500],
       [ 15,  16,  17,  18,  19],
       [ 20,  21,  22,  23,  24]])
: b
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14],
       [15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24]])
\end{lstlisting}
Changing the data in a copy of an array, doesn't change the data in the original array.  The two arrays address different locations in memory.

\subsubsection*{Slices}
Each element of an array has a unique address that we can use to retrieve that element.  Indexing NumPy arrays is syntatically the same as indexing Python lists.  We will demonstrate on a random 2D array.  Remember that slicing arrays always return views of the array.  In this case, the indexing object is a Python tuple.

\begin{lstlisting}
: arr = np.arange(25).reshape(5,5); arr
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14],
       [15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24]])
: arr[0, 0] #access the first element
0
: arr[-1, -1] #access the last element
24
: arr[0] #access the first row
array([0, 1, 2, 3, 4])
\end{lstlisting}
We can access ranges of elements using Python lists.
NumPy, though, has a much faster, more concise way to select ranges using the \li{arr[start:stop:step]} notation.

\begin{lstlisting}
: arr[::2] #get every other row.  equivalent to arr[range(0, len(arr), 2)]
array([[ 0,  1,  2,  3,  4],
       [10, 11, 12, 13, 14],
       [20, 21, 22, 23, 24]])
: arr[::2, ::2] #get every other row and every other column
array([[ 0,  2,  4],
       [10, 12, 14],
       [20, 22, 24]])
: arr[3:, 3:] #extract lower right 2x2 subarray
array([[18, 19],
       [23, 24]])
: arr[:, 1] #extract second column
array([ 1,  6, 11, 16, 21])
\end{lstlisting}

\subsubsection*{Fancy Indexing}
When the indexing object is an something other than a tuple, NumPy behaves a little differently.
One difference is that fancy indexes always return a copy of an array instead of a view.
There are two types of fancy indexes: boolean and integer.
Boolean indexing returns an array of \li{True} or \li{False} values depending on some evaluating condition.

\begin{lstlisting}
: bmask = (arr > 15) & (arr < 23)
array([[False, False, False, False, False],
       [False, False, False, False, False],
       [False, False, False, False, False],
       [False,  True,  True,  True,  True],
       [ True,  True,  True,  False,  False]], dtype=bool)
: arr[bmask]
array([16, 17, 18, 19, 20, 21, 22])
: arr[(arr > 15) & (arr < 23)] #this is the shortened form
array([16, 17, 18, 19, 20, 21, 22])
: arr[~bmask] #invert the mask
\end{lstlisting}

\begin{lstlisting}
: arr[(0, 2, 4), (0, 2, 4)] #grab every other element of diagonal
array([ 0, 12, 24])
: arr[range(0, 5, 2), range(0, 5, 2)] #same as above, but with ranges
array([ 0, 12, 24])
: arr[:, [0, -1]] #grab first and last column
array([[ 0,  4],
       [ 5,  9],
       [10, 14],
       [15, 19],
       [20, 24]])
\end{lstlisting}

\section*{The Transpose and Other Useful Operations}
You may have noticed that we used the \li{reshape} method of a NumPy array.
There is a corresponding \li{reshape} function.
Both of them allow us to make new view of our array with the shape we have specified.
The new shape must form an array with the same size as the original array.

If we need to take the transpose of an array \li{A}, we can use the transpose attribute of the array, \li{A.T}, which will give us a new view of the same array with the order of the dimensions reversed.

Remember that both of these methods will return views of the original array and not new arrays.

The functions \li{flatten}, \li{vstack}, \li{hstack}, and \li{copy} are examples of functions that will return new arrays.
Given a $3 \times 3$ array, \li{flatten} will return a new copy of the array with shape \li{(9)}, \li{vstack} will return a new copy of the array with shape \li{(9,1)}, \li{hstack} will return a new copy of the array  with shape \li{(1,9)}, and \li{copy} will return an exact copy of the array.

The syntax \li{A[:]} will return a new view of \li{A} that is identical to A.
This doesn't sound all that useful, but if you want to override the values in an array this syntax can be extremely useful.
For example:
\begin{lstlisting}
import numpy as np
from numpy.random import rand
A = rand(100)
B = rand(100)
A[:] = 0 #sets each entry in A to 0
A[:] = B #copies the data from B into A
\end{lstlisting}

\begin{problem}
Operations that create completely new arrays are generally slower than operations that just create views because they have to copy all of the data from the original array.
Make \li{A} a $1000 \times 1000$ array of floating point values.
Compare the speed of the operations \li{A.reshape(A.size)} and \li{A.flatten()}.
Why is there such a difference in speed?
What is the difference between their output?
\end{problem}

\begin{problem}
Let \li{A} be the an array with shape \li{(1,1000000)}.
What is the difference in the output between \li{np.vstack(A)} and \li{A.T}?
Which of the two is faster?
\end{problem}

\section*{Array Broadcasting}
Array broadcasting allows NumPy to effectively work with arrays with sizes that don't match exactly.
There are four basic rules to determine the behavior of broadcasted arrays.

\begin{remunerate}
\item All input arrays of lesser dimension than the input array with largest dimension have 1's prepended to their shapes.
\item The size in each dimension of the output shape is the maximum of all the input sizes in that dimension.
\item An input can be used in the calculation if its size in a particular dimension either matches the output size in that dimension, or has a value exactly 1.
\item If an input has a dimension size of 1 in its shape, the first data entry in that dimension will be used for all calculations along that dimension.
\end{remunerate}
To broadcast arrays, at least one of the following must be true.
\begin{remunerate}
\item All input arrays have exactly the same shape.
\item All input arrays are of the same dimension and the length of corresponding dimensions match or is 1.
\item All input arrays of fewer dimension can have 1 prepended to their shapes to satisfy the second criteria.
\end{remunerate}

One simple example is multiplying a two dimensional array by a set of numbers along its rows or columns.
Run the following lines of code and consider their output:
\begin{lstlisting}
import numpy as np
A = np.ones((3, 3))
B = np.vstack(np.array([1, 2, 3,]))
A * B #multiplies the rows of A by each entry of B
A * B.T #multiplies the columns of A by each entry of B
\end{lstlisting}

\begin{problem}
Explore array broadcasting.
Create an example for each of the three cases where arrays are broadcasted.
Don't just use the example already given.
\end{problem}

\section*{Saving Arrays}
Sometimes it is desirable to save an array to a file.
NumPy provides several easy to use methods for saving and loading array data.
\begin{table*}[h]
\begin{tabular}{|l|l|}
\hline
\li{np.save(file, arr)} & Save an array to a binary file \\
\li{np.savez(file, *arrs)} & Save multiple arrays to a binary file \\
\li{np.savetxt(file, arr)} & Save an array to a text file \\
\hline
\end{tabular}
\end{table*}

\begin{table*}[h]
\begin{tabular}{|l|l|}
\hline
\li{np.load(file)} & Load and return an array from a binary file \\
\li{np.loadtxt(file)} & Load and return an array from text file \\
\hline
\end{tabular}
\end{table*}

Let's practice saving an array to a file and loading it again.
Note that, when saving an array, NumPy automatically appends the extension \li{.npy} if it is not already present.
\begin{lstlisting}
a = np.arange(30)
np.save('test_arr', a)
new_a = np.load('test_arr.npy')
np.savez('test_multi', a=a, new_a=new_a)
arrs = np.load('test_multi.npz')
\end{lstlisting}
The variable \li{arrs} points to a dictionary object with the keys \li{a} and \li{new_a} which reference the arrays that have been saved.
The \li{.npz} file extension is the file type used to store multiple arrays.

