\lab{Python}{Generators}{Generators}
\label{lab:Python_Generators}

Lists, tuples, sets, and dictionaries are examples of sequences in Python.
Often it is useful to visit all the elements of a sequence.  This process of visiting
each element of a sequence once is called \emph{iteration}. 
Each of the Python types we have mentioned define their own iterators.
You use them every time you execute the statement \li{for <elem> in <list>}.
Python has a special type of object called a \emph{generator}.
Similar to an iterator, a generator returns a sequence of values.
The important difference is that a generator computes the next value in the sequence and returns it.
It never has to store all of the values in the sequence.
A good way to say this is: \emph{Iterators return their values while generators yield their values}.
In fact, Python uses the \li{yield} keyword to define a generator.
Let's illustrate the difference between iterating and generating by re-implementing Python's \li{range} function
as both an iterator and a generator.
\begin{lstlisting}
def range_iter(start, stop, step=1):
    i = start
    r = []
    while i < stop:
       r.append(i)
       i = i + step
    return r
\end{lstlisting}
\begin{lstlisting}
def range_gen(start, stop, step=1):
    i = start
    while i < stop:
        yield i
        i = i + step
\end{lstlisting}
The two functions look very similar.  But, you will soon see that they behave very differently.
The first function, when executed will immediately build a list, one element at a time until the done
at which point it returns the entire list.  On this authors computer, this function takes about 1.43ms
to build and return a list of 10000 elements.  The second function is only marginally better at
returning the 10000 elements in approximately 1.09ms.  
This gap between the two functions grows much wider as the inputs are increased.
Where the real difference in the two functions lies is in the time the function takes to execute when
it is first called.  The first function requires 1.43ms to execute the first time.  The second function,
a mere .00000041ms!  The reason for this is the first function calculates its results and returns them all at once.  The second function only creates a \emph{generator} object.  This object has several methods.
The most important and most useful method is the \li{next()} method.  Every time this method is called, 
the generator starts from its previous state and computes the next value in the sequence. Each time \li{yield} statement is executed, the generator is effectively suspended until \li{next()} is called again.
When the generator has finished executing, a \li{StopIteration} exception is raised the generator terminates.
You can send values and throw exceptions to the generators via the \li{send()} and \li{throw()} methods respectively.
For more information on these methods, see the Python documentation on generators.
The \li{xrange} function that is built into Python is a generator based version of the \li{range}.
It is recommended that you use xrange instead of range wherever possible because it is much faster and requires much less memory.
In Python 3, the \li{range} function has been made into a generator and the \li{xrange} function has been removed.
If you still need an actual list, you can use \li{list(range(...))}.

When are generators helpful? If you encounter the situations below, consider trying to solve 
your problem using generators.
\begin{itemize}
\item \emph{Iterating through only part of a sequence.}
It is inefficient to create an entire sequence if we know that we will not need all of it.
Representing the sequence as a generator could possibly avoid excess memory use and excess computation.
\item \emph{Iterating through a sequence once.} Consider the statement 
\li{sum([i for i in range(1000) if i\%2 == 0])}.
We are creating two sequences just to iterate through them once and never use them again.
We can make this more efficient using generators.
\li{sum(i for i in xrange(1000) if i\%2 == 0)}
Notice that we have used syntax similar to a list comprehension.
The line \li{(i for i in xrange(1000) if i\%2 == 0)} will define a generator object similar to the list made by \li{[i for i in xrange(1000) if i\%2 == 0]}.
The solution using generators will often execute faster, but it will almost always be more memory efficient.  Consider using generators for any function that reduces a sequence to a single value.  Examples of such functions are \li{min()}, \li{max()}, and \li{sum()}.
\item \emph{Calculating large sequences.}  The sequence must be stored somewhere in computer memory.
If the sequence is large, we could exhaust all available memory.
\item \emph{Calculations involving infinite sequences.}  Pre-computed sequences are necessarily finite.  We cannot create a list that stores all natural numbers, but we can create a generator that returns the next natural number every time it is called.
\end{itemize}


\section*{Combinations}
Combinations are subsets of a set.  The power set of a set, $S$, is the set of all combinations
of elements in $S$.  The cardinality of the the power set is $2^{\abs{S}}$.  Clearly, if our
set is of any appreciable size, the power set will be much larger.  Let's look at one method for
generating the power set of a set.

We can generate the power set of a set by representing each element in a set by one bit.
If the bit is 0, then we do not include the element in the current combination.  If the
bit is 1, the element is included in the combination.  Then we count from 0 to $2^{\abs{A}}$
and look as the binary representation of the number, including or excluding elements based
on the bits in their respective location.

\begin{problem}
Write a function that will accept a set of elements and return a list of all the combinations
of elements of that set.  You will have to impose some sort of ordering on the set (map each element
in the set to a position in the binary representation).
\end{problem}

This is, however, an inefficient way to generate combinations.  Ideally, we would want
to generate the next combination by modifying the previous combination.  However, with
our current method of counting in binary, we are rebuilding the combination from scratch
each time.  For example it we have a combination represented by \texttt{01111}, the next
combination would be \texttt{10000}.  We added one element and removed four elements!
It can be useful to get our next combination by changing the previous combination as little as possible.
Fortunately, there is a really neat way of doing this--Gray codes. 
A Gray code is a sequence of binary numbers where each new number is generated by
changing the previous code by exactly one bit.  Geometrically, we can think of it as
traversing a unit cube by moving only along the edges of the cube.
Because of this they are often called reflected binary codes.
Grey codes are used frequently in error correction schemes.

A Gray code is constructed as follows.
\footnote{Brualdi, Richard Brualdi. \emph{Introductory Combinatorics}. New Jersey: Pearson, 2009}
The Gray code of order $n$ can be calculated using recursion in the following way:
\begin{enumerate}
\item If $n=1$, return $\lbrace 0, 1\rbrace$.
\item Compute the Gray code of order $n-1$.  Write the binary numbers in a new list and then write them again in reverse order on the end of the same list (reflect them so that the last Gray code or order $n-1$ is first and the first Gray code of order $n-1$ is last).
\item Prepend a 0 to the first $2^{n-1}$ codes and prepend a 1 to the remaining $2^{n-1}$ codes.
\end{enumerate}
While this is a simple algorithm to describe, it is not very efficient.  
To generate a Gray code of order $n$, we have to generate all previous Gray codes.
If we were to calculate the Gray codes up to order 6, we would calculate the Gray code of order 6 once, order 5 twice, order 4 three times, order 3 four times, and order 2 five times!
Fortunately, there exists another way to compute Gray codes of order $n$ much more efficiently.
The algorithm is given in Brualdi's book.  
We first note that a Gray code of order $n$ is of length $2^n$ with each code of length $n$.
We also observe that the reflected gray codes always begin with $0\dots0$ and terminate with $10\dots0$.
\begin{enumerate}
\item Start with $0\dots0$ ($n$ zeros).  This is the current binary number.
\item Sum the digits of the current binary number.
\begin{enumerate}
\item If the sum of the digits is even, add 1 to the last digit mod 2.
This becomes our new current Gray and we go back to step 1.
\item If the sum of the digits is odd, find the rightmost non-zero digit and add 1 to the digit immediately to the left of it.
This becomes our new current number and we go back to step 1.
\item If the right most non-zero digit of the number is the first one you have reached the end of the Gray code.
\end{enumerate}
\end{enumerate}

\begin{problem}
\label{prob:brualdi_gray}
Implement the algorithm above for calculating the Gray code of order $n$.
Your implementation must function as a generator.
\end{problem}

\begin{problem}
\label{prob:changed_elem_gray}
Gray codes are an ordering of the power set such that any consecutive subsets differ by exactly one element.  Write a generator that will only return the change required to arrive at the next subset in the ordering.  Each time the generator is called, 
it should return a single element and a boolean value that determines if that element should be
added or removed from the set to obtain the next Gray code.  This function should be able to accept any set with arbitrary elements.
\end{problem}

\section*{Itertools}
There is a very powerful library in the Python Standard Library that is built around the concept
of generators and iterators.  The functions in \li{itertools} are designed to be used as
building blocks in larger functions.  These functions are fast and memory efficient.
We encourage you to view the documentation for \li{itertools} on the Python website.  Itertools has a much more general and much faster solutions for generating combinations and permutations of a set.
The generator that we have written as a solution to \ref{prob:changed_elem_gray} is especially useful when we are interested in the changed elements between successive subsets, or when we want to continuously update a single data structure using the elements of a Gray code.
The benefits of such an approach would be particularly apparent in cases where it is costly to add or remove items from the data sructure.
The documentation for \li{itertools} also includes various recipes for other useful generator functions.

\begin{problem}
\label{prob:subblocks}
Write a generator function that will evenly split a 1-dimensional array into sub-blocks.
Your function should be capable of returning sub-blocks that could possibly overlap.
The function should accept as arguments: a 1-dimensional array,
a block width, and an optional offset.  If the array cannot be evenly divided into
sub-blocks, raise and error.
\end{problem}

\begin{problem}
Expand your solution to Problem \ref{prob:subblocks} to work with 2-dimensional and 3-dimensional
arrays.  You may implement them as separate functions if you wish.
\end{problem}

\printbibliography

% \begin{thebibliography}{99}
% \bibitem{brualdi09}
% Richard Brualdi, 
% \emph{Introductory Combinatorics}.
% Pearson, New Jersey, 5th edition, 2009.
% 
% \end{thebibliography}
